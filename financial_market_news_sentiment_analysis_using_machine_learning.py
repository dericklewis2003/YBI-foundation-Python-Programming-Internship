# -*- coding: utf-8 -*-
"""Financial Market News Sentiment Analysis Using Machine Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QuGHR3p7AHQsfO2D8TK9bhvZR8WLFNz9

**Title of Project**
Financial Market News Sentiment Analysis Using Machine Learning

**Objective**
 To analyze the sentiment of financial news articles and predict its impact on the market using a Random Forest model.

Data Source

Dataset: /content/Financial Market News.csv

Import Libary
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score

"""Import Data"""

df = pd.read_csv('/content/Financial Market News.csv', encoding='latin-1') # Try 'latin-1' encoding

"""Describe Data"""

print(df.head())
print(df.info())
print(df.describe())

"""Data Visualization"""

# Visualize the distribution of sentiment labels
sns.countplot(x='Label', data=df)
plt.title('Distribution of Sentiment Labels')
plt.xlabel('Sentiment')
plt.ylabel('Count')
plt.show()

"""Data Processing"""

# Handling missing values and text cleaning
df = df.dropna()  # Drop rows with missing values

import re

def clean_text(text):
    text = re.sub(r'\s+', ' ', text)  # Remove extra whitespace
    text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
    return text

df['cleaned_text'] = df['News 1'].apply(clean_text)

"""Define Target Variable"""

X = df['cleaned_text']
y = df['Label']  # Assuming 'Label' contains sentiment labels

# Convert text to numerical features
vectorizer = TfidfVectorizer(max_features=5000)
X_vectorized = vectorizer.fit_transform(X)

# Train Test Split
X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)

"""Modeling"""

# Train Random Forest model
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

"""MOdel Evalution"""

y_pred = model.predict(X_test)
print("Accuracy Score:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

"""**Prediction**"""

# Example Data for Prediction
new_data = [
    "The stock market is experiencing a downturn due to recent economic reports.",
    "Investors are optimistic about the new technology innovations by major companies.",
    "There is uncertainty in the market as geopolitical tensions rise.",
    "Positive earnings reports are driving the market to new highs.",
    "Economic indicators suggest a possible recession in the coming months.",
    "Corporate profits have exceeded expectations, leading to a market rally.",
    "Concerns over inflation are causing volatility in the stock market.",
    "The central bank's decision to lower interest rates has boosted investor confidence."
]

# Clean and Vectorize New Data
new_data_cleaned = [clean_text(text) for text in new_data]
new_data_vectorized = vectorizer.transform(new_data_cleaned)

# Make Predictions
predictions = model.predict(new_data_vectorized)

# Map predictions to sentiment labels
sentiment_labels = {0: 'negative', 1: 'positive'}

# Print News and Predictions
for text, prediction in zip(new_data, predictions):
    print(f"News: {text}")
    print(f"Predicted Sentiment: {sentiment_labels[prediction]}")
    print()

